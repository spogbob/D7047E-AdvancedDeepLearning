{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exercise 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import scipy\n",
    "\n",
    "# Tensorboard for visualizing\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST('./files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "train_len = int(len(trainset) * 0.8)\n",
    "val_len = len(trainset) - train_len\n",
    "trainset, validationset = torch.utils.data.random_split(trainset, [train_len, val_len])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset,\n",
    "                             batch_size=4, shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(validationset,\n",
    "                             batch_size=1, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "                             batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 6, 4)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 4)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 84)\n",
    "        #self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.leaky_relu(self.conv1(x)))\n",
    "        x = self.pool(F.leaky_relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        #x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = Net();\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0002)\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 [12000/12000] - Loss: 0.11779198795557022365, accuracy:  0.9645\n",
      " (new best)\n",
      "Epoch 2 [12000/12000] - Loss: 0.03410159051418304426, accuracy:  0.9778333333333333\n",
      " (new best)\n",
      "Epoch 3 [12000/12000] - Loss: 0.0397364161908626569, accuracy:  0.9798333333333333\n",
      " (new best)\n",
      "Epoch 4 [12000/12000] - Loss: 0.00022887454542797064, accuracy:  0.9855\n",
      " (new best)\n",
      "Epoch 5 [12000/12000] - Loss: 0.02626394480466842764, accuracy:  0.9853333333333333\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "best_net = 0\n",
    "\n",
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(i % 100 == 99):\n",
    "            print(\n",
    "                f'\\rEpoch {epoch+1} [{i+1}/{len(train_loader)}] - Loss: {loss}',\n",
    "                end=''\n",
    "            )\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(val_loader, 0):\n",
    "        inputs, labels = data\n",
    "        labels = labels\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        pred = torch.argmax(outputs)\n",
    "\n",
    "        if pred.numpy() == labels[0].numpy():\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    writer.add_scalar(\"Validation/train\", correct/total, epoch)\n",
    "    print(\", accuracy: \", correct/total)\n",
    "    if correct / total > best_accuracy:\n",
    "        best_accuracy = correct / total\n",
    "        best_net = copy.deepcopy(model)\n",
    "        print(\" (new best)\")\n",
    "\n",
    "print('Finished Training')\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9858\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i, data in enumerate(test_loader, 0):\n",
    "    inputs, labels = data\n",
    "\n",
    "    outputs = best_net(inputs)\n",
    "    pred = torch.argmax(outputs)\n",
    "\n",
    "    if pred.numpy() == labels[0].numpy():\n",
    "        correct += 1\n",
    "    total += 1\n",
    "\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../SVHN/train_32x32.mat\n",
      "Using downloaded and verified file: ../SVHN/test_32x32.mat\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(SVHN_loader, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     35\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m---> 37\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mbest_net\u001b[49m(inputs)\n\u001b[1;32m     38\u001b[0m     pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pred\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m==\u001b[39m labels[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_net' is not defined"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.SVHN('../SVHN/', split='train', download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Resize(28),\n",
    "                               torchvision.transforms.Grayscale(1),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "train_len = int(len(trainset) * 0.8)\n",
    "val_len = len(trainset) - train_len\n",
    "trainset, validationset = torch.utils.data.random_split(trainset, [train_len, val_len])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset,\n",
    "                             batch_size=4, shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(validationset,\n",
    "                             batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "SVHN_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.SVHN('../SVHN/', split='test', download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Resize(28),\n",
    "                               torchvision.transforms.Grayscale(1),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "                             batch_size=1, shuffle=True)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for i, data in enumerate(SVHN_loader, 0):\n",
    "    inputs, labels = data\n",
    "\n",
    "    outputs = best_net(inputs)\n",
    "    pred = torch.argmax(outputs)\n",
    "\n",
    "    if pred.numpy() == labels[0].numpy():\n",
    "        correct += 1\n",
    "    total += 1\n",
    "\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 [14600/14652] - Loss: 2.4866814613342285, accuracy:  0.17915642915642915\n",
      " (new best)\n",
      "Epoch 2 [14600/14652] - Loss: 2.6639719009399414, accuracy:  0.17915642915642915\n",
      "Epoch 3 [10000/14652] - Loss: 2.123826503753662"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [85]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m     17\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     19\u001b[0m         inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     21\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/Documents/D7047E-AdvancedDeepLearning/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Documents/D7047E-AdvancedDeepLearning/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/Documents/D7047E-AdvancedDeepLearning/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/D7047E-AdvancedDeepLearning/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/D7047E-AdvancedDeepLearning/venv/lib/python3.8/site-packages/torch/utils/data/dataset.py:471\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 471\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Documents/D7047E-AdvancedDeepLearning/venv/lib/python3.8/site-packages/torchvision/datasets/svhn.py:102\u001b[0m, in \u001b[0;36mSVHN.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, Any]:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m        index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m        tuple: (image, target) where target is index of the target class.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(np\u001b[38;5;241m.\u001b[39mtranspose(img, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_tf = copy.deepcopy(best_net)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for param in model_tf.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#model_tf.fc2 = nn.Linear(84, 10)\n",
    "for param in model_tf.fc2.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "best_accuracy = 0\n",
    "#best_net = 0\n",
    "\n",
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model_tf(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if(i % 100 == 99):\n",
    "                print(\n",
    "                    f'\\rEpoch {epoch+1} [{i+1}/{len(train_loader)}] - Loss: {loss}',\n",
    "                    end=''\n",
    "                )\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate(val_loader, 0):\n",
    "        inputs, labels = data\n",
    "        labels = labels\n",
    "\n",
    "        outputs = model_tf(inputs)\n",
    "        pred = torch.argmax(outputs)\n",
    "\n",
    "        if pred.numpy() == labels[0].numpy():\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    writer.add_scalar(\"Validation/train\", correct/total, epoch)\n",
    "    print(\", accuracy: \", correct/total)\n",
    "    if correct / total > best_accuracy:\n",
    "        best_accuracy = correct / total\n",
    "        #best_net = copy.deepcopy(model)\n",
    "        print(\" (new best)\")\n",
    "\n",
    "print('Finished Training')\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0148, -0.1043, -0.0189,  0.0556,  0.0757,  0.0809,  0.0307, -0.0970,\n",
      "         -0.1001,  0.0385, -0.0188,  0.0866, -0.0299, -0.0508, -0.0799,  0.0582,\n",
      "          0.0822,  0.0041,  0.0653,  0.0345,  0.0432,  0.0683,  0.0985,  0.0739,\n",
      "          0.0154,  0.0056, -0.1088, -0.0731, -0.0035,  0.0906, -0.0565,  0.0718,\n",
      "         -0.0130, -0.0640,  0.0969,  0.0291, -0.0530,  0.0984,  0.0657,  0.0188,\n",
      "          0.0440, -0.0284,  0.1059,  0.1013, -0.0560, -0.0397, -0.0819, -0.1056,\n",
      "         -0.0844, -0.1052,  0.0151, -0.0156, -0.0195,  0.0976,  0.0970,  0.0433,\n",
      "         -0.0064,  0.0876, -0.0734,  0.0170, -0.0047,  0.0397, -0.0178,  0.0128,\n",
      "          0.0977, -0.0080, -0.1042, -0.0667,  0.1005,  0.0298, -0.0673, -0.0925,\n",
      "          0.0671,  0.0934,  0.0719, -0.0029, -0.0010,  0.0401, -0.0389, -0.0414,\n",
      "          0.0022,  0.0307, -0.0265,  0.0846],\n",
      "        [ 0.1040, -0.0953, -0.0077, -0.0382,  0.0774, -0.0511, -0.1073, -0.0053,\n",
      "         -0.0218, -0.0089, -0.0301, -0.0432, -0.0914, -0.0170, -0.1048,  0.0508,\n",
      "         -0.0455,  0.0908,  0.0548,  0.0925,  0.0761,  0.0901, -0.0282, -0.0095,\n",
      "         -0.0416,  0.0620, -0.1068, -0.1071, -0.0599, -0.0354, -0.0033,  0.0605,\n",
      "         -0.0555, -0.0800, -0.0412,  0.0985, -0.0979, -0.0922,  0.1023,  0.0976,\n",
      "         -0.0744,  0.0605, -0.0569, -0.0059,  0.0896, -0.0852,  0.0751,  0.0751,\n",
      "          0.0390, -0.0196, -0.0053,  0.0698,  0.0143, -0.0367, -0.0281, -0.0560,\n",
      "         -0.0013,  0.1000, -0.0652, -0.0614, -0.0431,  0.0215,  0.0536,  0.0329,\n",
      "         -0.0807, -0.0190,  0.0037, -0.0883,  0.0133,  0.0071,  0.0746, -0.1017,\n",
      "          0.0658,  0.0179,  0.0298,  0.0131,  0.0127,  0.0326, -0.0657,  0.0831,\n",
      "          0.0123, -0.0723, -0.0421, -0.1015],\n",
      "        [ 0.1090,  0.0660, -0.0490,  0.0764,  0.0987,  0.0489,  0.0682,  0.0655,\n",
      "          0.1055,  0.0325, -0.0815,  0.0370,  0.0893,  0.0549, -0.0105, -0.0627,\n",
      "         -0.0712,  0.0800, -0.0220, -0.0728, -0.0646,  0.0796, -0.1086,  0.0658,\n",
      "         -0.0671,  0.0070, -0.0902, -0.0615, -0.0278,  0.1066,  0.0841, -0.0574,\n",
      "          0.0758,  0.0202, -0.0285,  0.0311, -0.0807,  0.0240, -0.0697,  0.0696,\n",
      "          0.0217,  0.0429,  0.0746,  0.0652,  0.0474,  0.0455,  0.0118,  0.0856,\n",
      "          0.0650,  0.0022,  0.0661,  0.1088,  0.0743,  0.1038, -0.1012,  0.0287,\n",
      "          0.0095,  0.0700,  0.0919, -0.0493, -0.0251, -0.0742, -0.0538, -0.0371,\n",
      "          0.0178, -0.0752, -0.0436,  0.0307, -0.0978,  0.0047, -0.1048,  0.0608,\n",
      "         -0.0194, -0.0404, -0.0028, -0.0562, -0.0730,  0.0937, -0.0381, -0.0246,\n",
      "          0.0401,  0.0955, -0.0222,  0.0059],\n",
      "        [-0.0498,  0.0274, -0.1007, -0.1022,  0.0778,  0.0097,  0.0592,  0.0350,\n",
      "          0.0481, -0.0458, -0.0376,  0.0342, -0.0233, -0.0940,  0.0979, -0.0590,\n",
      "         -0.0297,  0.0413, -0.0443,  0.1033, -0.0704,  0.0974,  0.0076, -0.0231,\n",
      "          0.0573,  0.0074,  0.0361,  0.0420,  0.0294, -0.0754, -0.0717, -0.0392,\n",
      "          0.0531, -0.0757, -0.0067,  0.0635,  0.0530,  0.0576, -0.0536,  0.0315,\n",
      "          0.0482,  0.0450,  0.0793, -0.0034,  0.0887, -0.0789, -0.0122,  0.0797,\n",
      "          0.0784,  0.0339,  0.1076, -0.0003, -0.0147, -0.0036,  0.0256, -0.0961,\n",
      "         -0.0017,  0.0701, -0.0561, -0.1038, -0.0429, -0.0872,  0.0840, -0.0401,\n",
      "          0.0172,  0.0256, -0.0143,  0.0158,  0.0750, -0.0180, -0.0576,  0.0280,\n",
      "         -0.0280,  0.0180,  0.0555,  0.0667,  0.0150, -0.1067,  0.0244,  0.0658,\n",
      "         -0.0911,  0.0490,  0.0069, -0.0057],\n",
      "        [ 0.0721, -0.0163,  0.0844,  0.0775, -0.0668,  0.0619, -0.0211,  0.0421,\n",
      "          0.0242, -0.0694, -0.0910,  0.0120,  0.0283,  0.0240,  0.0545, -0.0192,\n",
      "         -0.0756,  0.0643, -0.0552,  0.1044,  0.0192, -0.0643, -0.0982,  0.0032,\n",
      "         -0.0443,  0.0333, -0.0870, -0.0645,  0.0063,  0.0119,  0.0053,  0.0727,\n",
      "          0.0452, -0.0126,  0.0788,  0.0927,  0.0045,  0.0601,  0.0708,  0.0019,\n",
      "         -0.0591, -0.0234, -0.0913,  0.0956,  0.0786, -0.0453,  0.0136,  0.1009,\n",
      "         -0.0972,  0.0060, -0.0860, -0.0151,  0.0075, -0.0396,  0.0960,  0.0246,\n",
      "          0.0689, -0.0798,  0.0721, -0.0282,  0.0139, -0.0857,  0.0795,  0.0107,\n",
      "         -0.0560, -0.0756,  0.0276,  0.0591, -0.0456,  0.0649,  0.0277,  0.0008,\n",
      "          0.0201, -0.1060,  0.0455,  0.1088,  0.0665,  0.0663,  0.0059,  0.0364,\n",
      "          0.0537,  0.0535, -0.0393,  0.0952],\n",
      "        [ 0.0820, -0.0284,  0.0876, -0.0873, -0.0703, -0.0512,  0.0815, -0.0579,\n",
      "         -0.0101,  0.0331, -0.0315,  0.0322, -0.0825,  0.0271,  0.0014, -0.0329,\n",
      "          0.0567, -0.0156, -0.0694,  0.0211, -0.0267, -0.1088,  0.0360, -0.0938,\n",
      "         -0.0412,  0.0653,  0.0577,  0.0222,  0.0944, -0.0303, -0.0925,  0.0853,\n",
      "          0.0495, -0.0059, -0.0431, -0.0289,  0.0962,  0.0467,  0.0123, -0.0078,\n",
      "          0.0621, -0.0115,  0.0902,  0.1031, -0.0309, -0.0957, -0.0674,  0.0522,\n",
      "          0.0482, -0.0913,  0.0799,  0.0214,  0.0070,  0.0763, -0.0377, -0.1019,\n",
      "          0.0783,  0.1076, -0.0835, -0.0274,  0.0188,  0.0263,  0.0471, -0.0557,\n",
      "          0.0801, -0.0279, -0.0550, -0.0448, -0.0938, -0.0768, -0.0738, -0.0797,\n",
      "          0.0680,  0.0929, -0.0658, -0.0270, -0.0861,  0.0969, -0.0822,  0.0972,\n",
      "         -0.0532,  0.0102,  0.0428, -0.0203],\n",
      "        [-0.0268,  0.1080,  0.0761, -0.0894,  0.0152, -0.0751, -0.0119,  0.0310,\n",
      "         -0.0119, -0.0269, -0.0630, -0.0031, -0.0398,  0.0753,  0.0629,  0.0535,\n",
      "         -0.0993,  0.0457,  0.0255, -0.0072,  0.0189, -0.0642, -0.0851, -0.0709,\n",
      "         -0.0616,  0.0985,  0.1045,  0.0698,  0.0889,  0.0643, -0.0663, -0.0581,\n",
      "         -0.0733, -0.0016,  0.0534, -0.0467,  0.0665, -0.0467,  0.0717,  0.0369,\n",
      "         -0.0183,  0.0654,  0.0185, -0.0799,  0.0826,  0.0378, -0.0540, -0.0660,\n",
      "          0.0871,  0.0872, -0.0785,  0.0646,  0.0489,  0.0952,  0.0847, -0.0076,\n",
      "          0.0450, -0.0187, -0.0890,  0.0584, -0.0309,  0.1032, -0.0670,  0.0654,\n",
      "         -0.0252, -0.0829,  0.0323,  0.0940,  0.0431,  0.0841,  0.0980,  0.0634,\n",
      "          0.0961, -0.0538,  0.0021,  0.1089,  0.0833,  0.0565, -0.0653, -0.0893,\n",
      "         -0.0852, -0.1089,  0.0954, -0.0899],\n",
      "        [-0.0309,  0.0880, -0.0588,  0.0397,  0.0396, -0.0983, -0.0042, -0.0114,\n",
      "          0.0313,  0.0582,  0.0239, -0.0417, -0.0393,  0.0859, -0.0780, -0.0504,\n",
      "         -0.0884, -0.0616, -0.0316,  0.0875, -0.0963, -0.0331,  0.0668, -0.0723,\n",
      "         -0.0367,  0.0197, -0.0029,  0.0252, -0.0013,  0.1027, -0.1012,  0.0587,\n",
      "          0.0975,  0.0465,  0.1000,  0.1030,  0.0700, -0.0107, -0.0502,  0.0135,\n",
      "          0.0645,  0.0478, -0.0731, -0.0461, -0.0010, -0.0045, -0.0790,  0.0104,\n",
      "          0.0115, -0.0689,  0.0294,  0.0945, -0.0917,  0.0592,  0.0078,  0.1029,\n",
      "          0.0134,  0.0667,  0.0538, -0.0270,  0.0822, -0.0377, -0.0026,  0.0220,\n",
      "         -0.0309, -0.0463,  0.0109,  0.0361, -0.0702,  0.0818, -0.0145,  0.0997,\n",
      "          0.0392, -0.0751,  0.0527, -0.0628,  0.0815,  0.0382, -0.0620,  0.0003,\n",
      "         -0.0723, -0.0881,  0.0108,  0.0547],\n",
      "        [-0.0272,  0.0167, -0.0136, -0.0461, -0.0534, -0.0257,  0.0864, -0.0343,\n",
      "          0.0456, -0.1071, -0.0788, -0.0924,  0.0264,  0.0862, -0.0363,  0.1025,\n",
      "          0.0281, -0.0606, -0.0287, -0.0422, -0.0879, -0.0806, -0.0735, -0.0368,\n",
      "          0.0680,  0.0062, -0.0169, -0.0312,  0.0700, -0.0532, -0.0833,  0.0595,\n",
      "          0.0640,  0.0004, -0.0965, -0.0083, -0.0519,  0.0310,  0.0370, -0.0208,\n",
      "          0.0414, -0.0269, -0.0101, -0.0313,  0.0741, -0.1026, -0.0125, -0.0704,\n",
      "          0.0594,  0.0785, -0.0521,  0.0473,  0.0135, -0.0449, -0.0216, -0.0193,\n",
      "          0.0026, -0.0408,  0.1041, -0.0726,  0.0285, -0.0534,  0.1067,  0.0055,\n",
      "         -0.0192,  0.0958, -0.0548,  0.0633, -0.0729,  0.0928, -0.0907,  0.0891,\n",
      "          0.0905, -0.0307, -0.0569, -0.0814,  0.0957,  0.0998,  0.0994, -0.0911,\n",
      "          0.0948,  0.0377, -0.0108,  0.0977],\n",
      "        [-0.0360,  0.0745, -0.0931, -0.0112,  0.0744, -0.0933,  0.0146, -0.1085,\n",
      "         -0.0568,  0.0476, -0.0170,  0.0866, -0.1027, -0.0029, -0.0538,  0.0193,\n",
      "         -0.0409, -0.0465,  0.0275,  0.0206, -0.0496, -0.0651, -0.0505, -0.0836,\n",
      "         -0.0363,  0.0471,  0.0675, -0.0757,  0.0672,  0.0357, -0.0181,  0.0457,\n",
      "          0.0064, -0.0266,  0.0384, -0.0869, -0.1049,  0.0339, -0.0944, -0.0944,\n",
      "          0.0891,  0.0151,  0.0224,  0.0122, -0.1055, -0.0260, -0.1067, -0.0284,\n",
      "         -0.0555,  0.0360,  0.0190, -0.0203, -0.0435,  0.0665, -0.1040, -0.0720,\n",
      "          0.0164,  0.0856, -0.0480,  0.0385, -0.0732,  0.0759,  0.1037, -0.0337,\n",
      "         -0.0152, -0.0270, -0.1070,  0.1024, -0.0957,  0.0047, -0.0869,  0.0543,\n",
      "         -0.0264, -0.0019, -0.0164, -0.0660, -0.0226,  0.0737,  0.1027,  0.0743,\n",
      "         -0.0458,  0.0363, -0.0932,  0.0712]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model_tf.fc2.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-3.2681e-02,  3.6461e-02,  8.8861e-02,  2.8648e-02, -6.0319e-02,\n",
      "          5.3470e-02,  1.2102e-01, -1.6033e-01, -1.7290e-01,  1.0319e-01,\n",
      "         -1.0360e-01,  9.5339e-02, -4.7467e-02,  9.2280e-02,  3.9894e-02,\n",
      "          3.3716e-03,  1.8028e-02, -2.5105e-02,  4.6425e-02, -1.9504e-01,\n",
      "         -1.6906e-01,  9.8276e-03,  1.5334e-02,  1.0193e-01, -1.3571e-01,\n",
      "         -2.0996e-01,  1.0975e-01, -1.4418e-01,  8.1126e-02,  2.2326e-02,\n",
      "         -2.1056e-01, -1.4813e-01, -1.1161e-01, -3.3030e-03, -3.3783e-02,\n",
      "         -1.7567e-02, -1.8456e-01,  1.8220e-02,  1.1045e-01,  3.3573e-02,\n",
      "         -5.4915e-02,  4.3983e-02,  7.8056e-02, -2.8809e-01, -9.7631e-02,\n",
      "          6.2399e-02, -1.2876e-01, -7.8045e-02, -1.4480e-02,  6.1431e-02,\n",
      "         -4.5326e-02,  4.1319e-02,  8.0601e-02,  2.4876e-01,  1.0518e-01,\n",
      "         -5.2108e-02, -1.5431e-01, -1.9858e-02, -1.8752e-01, -1.2958e-01,\n",
      "         -1.7929e-01,  9.6461e-02, -5.8395e-02,  7.9012e-02, -7.4403e-02,\n",
      "          2.1461e-02, -2.2590e-01,  1.1767e-01, -7.9781e-02, -1.2962e-01,\n",
      "          1.2163e-01, -1.0540e-01,  3.0043e-02, -5.8296e-02, -2.0553e-01,\n",
      "         -6.7941e-02, -3.5447e-02,  5.3003e-02,  8.2616e-02,  1.0489e-01,\n",
      "          6.8589e-02, -9.8229e-04,  5.3139e-02,  9.8004e-02],\n",
      "        [-1.1650e-01,  2.6575e-02,  1.2872e-01, -1.8687e-01,  9.1542e-02,\n",
      "         -1.2961e-01, -6.5827e-03, -1.3947e-01, -1.1252e-01, -9.8919e-03,\n",
      "         -1.6363e-01,  1.2437e-02, -1.1293e-01, -9.6059e-02,  1.9994e-02,\n",
      "          9.6779e-02, -2.0761e-01,  8.8547e-02, -8.3492e-02,  1.4230e-01,\n",
      "          4.5102e-02,  7.5298e-02, -1.3184e-01,  5.5536e-02,  5.4728e-02,\n",
      "          7.9130e-02,  5.8674e-02,  5.1768e-03,  8.1321e-02,  1.0976e-01,\n",
      "          1.2482e-01,  1.0974e-01,  1.2228e-01, -9.7969e-03,  5.7242e-02,\n",
      "         -2.1574e-01,  3.1561e-02,  9.9558e-02,  2.4346e-02,  1.9670e-02,\n",
      "         -1.1359e-01, -1.3372e-01, -1.5433e-01,  1.4417e-01, -6.3735e-02,\n",
      "          4.1117e-02, -1.7790e-01, -3.8654e-02,  7.7315e-02, -8.3990e-02,\n",
      "         -2.1452e-01, -1.5733e-01,  7.5381e-02, -3.7336e-02, -8.4791e-02,\n",
      "          1.9831e-03,  1.3007e-01, -2.4668e-01, -1.8001e-02,  7.1793e-02,\n",
      "         -9.4687e-02, -1.3030e-01,  1.0834e-01, -5.4619e-02, -1.1059e-01,\n",
      "          9.9873e-02, -1.2724e-01,  4.4283e-02, -6.8331e-02,  2.4416e-02,\n",
      "         -1.4736e-01,  9.0726e-02,  7.4800e-02, -9.0844e-02, -2.0834e-01,\n",
      "         -1.7742e-01,  4.3189e-02, -8.5491e-02, -2.2113e-01, -1.0910e-01,\n",
      "         -2.1639e-01, -2.3705e-01,  1.6022e-01,  2.0275e-01],\n",
      "        [ 3.5642e-02, -6.7461e-02, -2.3445e-01,  5.6406e-02,  6.5913e-03,\n",
      "          2.3882e-02,  1.0591e-01,  3.0330e-02,  2.9338e-02,  8.8136e-02,\n",
      "          1.5242e-01,  5.1419e-02,  2.6572e-02, -2.0034e-02,  8.7886e-02,\n",
      "         -2.7159e-01, -5.7678e-02,  4.0150e-02,  1.9383e-02, -1.1605e-01,\n",
      "          7.6726e-02, -5.4253e-02, -1.7164e-01,  1.9987e-01,  9.9065e-02,\n",
      "         -2.0275e-01,  1.3773e-01,  8.2448e-02,  1.9689e-01, -8.5227e-02,\n",
      "          8.7905e-02,  4.9224e-02, -1.7178e-01,  1.2390e-01, -1.0360e-01,\n",
      "         -1.1593e-01,  5.1193e-02, -3.1654e-01, -4.5223e-02, -1.8972e-01,\n",
      "          2.4489e-02,  9.4832e-02,  3.9653e-02,  1.0772e-01,  1.0250e-01,\n",
      "         -3.9382e-01,  1.0110e-02, -1.7923e-01, -9.6677e-02,  3.6869e-02,\n",
      "         -1.2936e-01, -7.5771e-02,  1.6562e-02,  1.5081e-01, -6.6240e-02,\n",
      "         -7.1812e-02,  1.7952e-02,  1.0332e-01, -2.3190e-01,  6.2759e-02,\n",
      "         -8.5869e-02, -2.6227e-01,  6.1572e-02, -4.9926e-02,  1.3156e-01,\n",
      "          1.6234e-02,  1.1659e-01,  8.0666e-02, -1.8118e-01, -1.5460e-01,\n",
      "          6.7252e-02,  1.4353e-01,  5.2399e-02,  8.2352e-02,  1.8340e-02,\n",
      "          6.5340e-02, -9.5725e-02,  1.1613e-01, -7.5841e-02,  5.5946e-02,\n",
      "         -1.7389e-01, -7.0962e-02,  8.8871e-02, -2.0331e-02],\n",
      "        [ 1.6111e-01, -1.7761e-01, -2.5067e-01,  2.3341e-02, -2.5221e-02,\n",
      "         -3.2721e-02, -7.0576e-02,  8.6898e-02, -2.4625e-01,  1.1960e-01,\n",
      "         -2.0941e-01, -5.2895e-02, -5.0649e-02,  1.3713e-01, -1.9110e-01,\n",
      "         -1.4281e-01,  1.8678e-01, -1.2781e-02,  1.1095e-03, -8.6265e-02,\n",
      "         -1.4680e-01, -9.4718e-02, -2.1477e-01, -8.0467e-02, -1.3176e-01,\n",
      "          1.2879e-01, -1.7731e-01,  1.0118e-01, -1.5466e-01,  1.2790e-01,\n",
      "          5.5831e-03,  6.1013e-02,  6.3894e-02,  9.5991e-03, -1.9362e-01,\n",
      "          2.3880e-02, -1.4548e-01,  1.3799e-01, -5.1858e-03, -2.2243e-01,\n",
      "         -7.8536e-02, -1.9848e-04, -7.5829e-02, -1.9186e-01,  9.8864e-02,\n",
      "         -2.4822e-02, -1.0569e-01, -2.9104e-02, -3.0344e-01, -1.8982e-01,\n",
      "          1.3060e-01,  7.9108e-02,  7.7286e-02, -1.4277e-01, -2.5654e-01,\n",
      "         -2.3931e-01, -2.5756e-02, -7.7892e-02,  7.4470e-02,  9.7866e-02,\n",
      "         -1.0011e-01, -1.5542e-02, -7.9280e-02,  5.0292e-02, -2.9147e-02,\n",
      "         -6.8237e-02, -5.9771e-03, -1.9713e-01,  1.7119e-02,  1.0664e-01,\n",
      "          8.8304e-02,  6.7585e-03,  3.2479e-02,  1.3679e-01,  6.2840e-02,\n",
      "          2.0769e-02,  7.4402e-02, -2.6375e-01,  1.4366e-01, -1.3361e-01,\n",
      "         -6.8228e-02,  3.0607e-02, -1.9289e-03,  1.2006e-01],\n",
      "        [-1.8085e-01,  5.3637e-02, -1.1325e-01, -1.8162e-01, -1.7433e-01,\n",
      "          4.2743e-02,  2.6093e-02, -6.7730e-02,  1.7789e-01,  2.6666e-02,\n",
      "          8.4874e-03, -2.4934e-01, -1.3746e-01, -3.5998e-01,  8.8567e-02,\n",
      "          4.6386e-02, -6.3307e-02, -1.2971e-01,  1.4073e-01,  1.4977e-01,\n",
      "         -8.3557e-02, -4.5082e-02, -1.1400e-01, -1.0734e-01,  5.0964e-02,\n",
      "          1.3581e-02,  1.1991e-01, -1.4902e-01, -1.9531e-02, -3.8983e-02,\n",
      "         -2.8095e-02, -7.5503e-02, -7.5518e-02,  1.1115e-01,  9.5263e-02,\n",
      "          3.0927e-02,  6.0042e-02,  2.5731e-02, -2.0441e-01,  1.2607e-01,\n",
      "         -5.9157e-02, -2.5293e-01,  8.0543e-02,  4.0577e-02,  5.7381e-02,\n",
      "         -1.8669e-01,  8.4920e-02, -2.3488e-02,  1.6097e-01, -1.6961e-01,\n",
      "          2.8378e-02, -1.6397e-01,  7.5602e-02, -1.6796e-01, -2.3733e-02,\n",
      "         -4.0106e-02, -2.7044e-01,  1.6218e-01,  1.3061e-01,  1.6908e-02,\n",
      "          5.8117e-02,  1.4229e-01, -1.6005e-01,  6.1584e-02,  1.8600e-01,\n",
      "          7.1918e-02, -1.1921e-02,  7.3890e-02,  5.8035e-02,  6.9356e-02,\n",
      "         -1.6434e-01,  1.8370e-02, -1.4018e-02, -1.2075e-01, -1.3417e-01,\n",
      "         -4.6818e-02,  5.0722e-02, -1.0653e-01,  1.6949e-02,  4.2458e-02,\n",
      "          7.3028e-02, -9.9494e-02,  4.9651e-02, -1.3845e-01],\n",
      "        [-1.0853e-01,  1.6719e-01, -1.5753e-01, -1.5545e-01, -2.6812e-02,\n",
      "          4.4371e-02,  6.3551e-02, -7.9455e-02, -1.3473e-01, -1.3774e-01,\n",
      "         -2.3294e-02, -1.3302e-01, -4.3497e-02,  1.0034e-01, -4.3708e-02,\n",
      "          9.1115e-03,  4.6392e-02, -4.7356e-02, -4.9219e-02, -1.9274e-01,\n",
      "         -1.4201e-01,  2.0336e-02,  1.3100e-01, -1.4751e-01, -8.3045e-02,\n",
      "          3.5841e-02, -1.5971e-01,  5.5590e-02, -1.9058e-01, -1.8483e-01,\n",
      "         -7.4515e-02,  1.1515e-01,  2.0500e-01, -2.3072e-01, -3.5258e-03,\n",
      "         -8.3323e-02,  5.0868e-02,  7.7749e-02,  3.2448e-02,  7.5423e-02,\n",
      "          2.2266e-02,  8.3882e-03, -9.2924e-02,  6.3128e-02, -2.0296e-01,\n",
      "          1.2329e-02,  3.9345e-02,  5.7809e-02,  3.0912e-02,  4.0330e-02,\n",
      "         -7.8246e-03,  2.3935e-02, -1.8430e-01,  3.9464e-02, -1.0061e-01,\n",
      "          6.9672e-02,  2.9412e-02, -4.7976e-02, -9.6845e-02, -2.0461e-02,\n",
      "          1.1995e-01, -1.8686e-01,  9.6837e-02, -1.2224e-01,  4.7618e-02,\n",
      "         -1.1196e-01,  7.0176e-02, -1.1358e-01,  1.3496e-01,  8.0662e-02,\n",
      "          6.9973e-02, -1.4222e-01, -1.4190e-01,  8.8487e-02,  1.3250e-01,\n",
      "         -2.0258e-01,  3.0376e-02, -4.8595e-02,  1.0842e-01, -4.5528e-02,\n",
      "          4.9304e-02,  9.2188e-02,  2.3352e-02,  1.1635e-01],\n",
      "        [-3.0548e-02,  1.0063e-01,  1.5882e-01, -2.9967e-02, -9.6356e-02,\n",
      "         -2.6008e-01,  1.2224e-01, -4.7188e-02, -2.7099e-01,  5.8631e-02,\n",
      "         -5.8221e-02, -9.7603e-02, -1.7855e-01, -4.7183e-02,  5.4328e-02,\n",
      "          1.1182e-01,  1.3192e-01,  8.1233e-02, -1.8675e-01, -2.6284e-02,\n",
      "         -1.1453e-01,  1.0042e-01, -5.7561e-03,  1.6746e-01, -1.6720e-01,\n",
      "         -1.3262e-02, -1.0667e-01, -3.5158e-02,  3.5815e-02, -2.5692e-01,\n",
      "         -1.3219e-01, -1.1008e-02, -1.0769e-01,  1.8459e-02,  1.2768e-01,\n",
      "          9.6689e-02,  2.5297e-02, -9.8899e-02,  3.5362e-02, -6.6070e-03,\n",
      "          1.8925e-01,  8.2059e-03,  1.6441e-02, -4.0553e-02, -4.6681e-02,\n",
      "         -2.5541e-02,  6.8537e-02,  1.1585e-01, -1.4043e-01, -1.0212e-02,\n",
      "         -8.5385e-02, -8.8455e-02, -1.7231e-01, -1.7722e-01,  1.4044e-01,\n",
      "          1.0303e-01, -8.1106e-02,  1.0552e-01, -1.8908e-01, -1.2320e-01,\n",
      "         -2.2396e-01,  1.5157e-01, -5.9254e-02, -1.3923e-01,  2.3512e-02,\n",
      "         -2.5431e-01, -9.8187e-02, -4.0437e-02,  7.7817e-02, -9.0557e-03,\n",
      "          7.0131e-02, -1.4353e-01, -3.2957e-01, -1.3390e-01,  7.2983e-02,\n",
      "          1.5505e-03,  6.6279e-02, -1.4349e-01,  4.6213e-02,  8.1878e-02,\n",
      "          2.6624e-03, -7.6648e-02,  8.7536e-02, -2.2035e-01],\n",
      "        [-1.0704e-01, -2.7599e-01, -1.5082e-01,  7.8227e-02, -1.5900e-01,\n",
      "          4.2048e-02, -1.4935e-01,  9.9284e-02, -2.0837e-01,  2.2983e-03,\n",
      "          1.1501e-01,  6.0508e-02, -1.2162e-01, -1.6759e-01, -3.3147e-02,\n",
      "         -2.0440e-01,  4.8431e-02,  8.9408e-02,  8.0055e-02, -9.8569e-02,\n",
      "         -1.4733e-02, -2.7177e-01,  1.8397e-01, -1.7909e-01,  1.1515e-01,\n",
      "          3.1221e-02,  8.4308e-02, -1.0696e-01,  2.0592e-01,  1.2220e-01,\n",
      "         -4.0543e-02,  1.1946e-01, -6.1430e-02, -1.8376e-01, -1.5034e-01,\n",
      "          1.0708e-01, -1.9317e-01, -1.5049e-01, -7.1812e-02,  7.6433e-02,\n",
      "          7.2832e-02, -3.4548e-02, -2.2225e-01, -2.0965e-01, -9.0881e-02,\n",
      "         -4.2661e-02, -1.5078e-01, -1.4344e-01,  4.0059e-03, -2.2429e-02,\n",
      "          1.0871e-02,  1.2695e-01,  1.0719e-01, -1.8647e-01,  1.5738e-01,\n",
      "         -1.0799e-01,  3.4838e-02, -2.0325e-01,  9.9048e-02,  1.1641e-01,\n",
      "          1.5767e-01,  3.6322e-02,  5.4441e-02,  3.3767e-02,  2.2319e-02,\n",
      "          1.2187e-01, -6.8310e-03, -4.9428e-02,  8.5209e-02,  8.9023e-02,\n",
      "         -1.1597e-01,  1.1239e-01,  6.9880e-02, -1.2222e-01, -2.2187e-02,\n",
      "         -1.1888e-01,  1.3034e-02, -5.9532e-02,  3.8044e-02, -5.4265e-02,\n",
      "         -1.2343e-01,  6.2068e-02,  1.1677e-01, -8.3715e-02],\n",
      "        [-2.2736e-02, -2.8251e-02, -1.5674e-01,  1.1845e-01,  6.4355e-02,\n",
      "         -1.0983e-01,  8.7703e-02,  1.0916e-02,  8.1890e-02, -4.3848e-02,\n",
      "         -8.8641e-02,  8.7888e-02,  8.7706e-02, -5.5425e-03, -1.3104e-01,\n",
      "          5.4313e-02, -8.0075e-02,  8.0285e-02,  5.4094e-02, -2.4060e-01,\n",
      "          1.3656e-01,  7.5727e-02, -1.5509e-01, -1.4314e-01,  5.6898e-02,\n",
      "          1.1011e-01, -1.7662e-01, -7.9286e-02, -1.5279e-01, -1.1185e-01,\n",
      "         -6.1363e-02, -3.7975e-02, -2.1520e-01,  1.3112e-02,  8.5802e-02,\n",
      "         -5.5492e-02,  1.4563e-01,  2.7877e-02, -2.7673e-02,  6.7381e-02,\n",
      "         -1.9626e-01, -4.7561e-02,  1.2088e-01, -6.9301e-02,  6.0318e-02,\n",
      "         -1.2899e-01,  1.1809e-01,  8.9761e-02, -1.8971e-01,  2.7942e-02,\n",
      "          1.0604e-02,  1.0960e-01,  1.0519e-01, -1.6916e-01,  3.5229e-02,\n",
      "          7.4370e-02, -1.8158e-01, -2.2127e-01, -2.9416e-01,  1.0046e-02,\n",
      "         -1.7460e-01, -8.6405e-02, -2.1492e-02,  6.0620e-03, -2.5544e-01,\n",
      "          8.4549e-02, -1.6650e-02, -1.0899e-01, -5.5622e-02,  7.7239e-02,\n",
      "          1.4724e-01,  8.1603e-02, -2.1916e-02, -1.0877e-01,  1.4502e-01,\n",
      "         -3.3433e-02, -4.4341e-02, -9.2280e-02, -3.8011e-02, -5.2352e-02,\n",
      "          3.3993e-02,  1.1607e-01,  3.5382e-02, -1.4933e-02],\n",
      "        [-4.3987e-02,  1.9442e-02, -2.5316e-02, -1.4409e-02, -7.3707e-02,\n",
      "          5.5772e-02, -1.4203e-01,  1.1222e-01,  1.3715e-01, -2.2228e-01,\n",
      "         -4.9891e-02,  7.7156e-02,  7.6508e-02, -5.7075e-02,  1.2434e-01,\n",
      "          5.7605e-02, -3.2508e-02, -2.3255e-01,  1.0881e-01, -3.4322e-02,\n",
      "          4.0684e-02,  9.7696e-05, -6.0861e-02, -7.1556e-03, -1.5741e-02,\n",
      "         -8.8242e-02, -6.3322e-02,  1.3272e-01, -1.6339e-01,  9.1351e-02,\n",
      "          1.5642e-02,  7.1018e-02, -7.3555e-02, -7.8275e-03,  2.0386e-02,\n",
      "         -4.7039e-02, -6.5877e-02,  9.3287e-02, -8.1035e-02,  7.8335e-02,\n",
      "         -1.3889e-01, -1.1212e-01,  4.3344e-02, -1.7150e-01, -1.0299e-01,\n",
      "          2.1383e-01,  4.2624e-02,  3.4298e-02, -1.3884e-01, -3.3150e-02,\n",
      "          9.9109e-02, -6.4777e-02,  5.1978e-02, -5.6879e-02, -8.3186e-03,\n",
      "         -1.5643e-01, -1.4299e-01,  1.4890e-01,  1.6273e-01, -1.2113e-01,\n",
      "          1.4651e-01,  7.2651e-02,  5.0147e-02,  9.2610e-02,  4.2937e-02,\n",
      "         -4.9195e-02,  1.6218e-02, -8.1146e-02,  8.7398e-02,  1.0790e-01,\n",
      "         -4.5483e-02, -1.2630e-01,  5.3193e-02, -3.7610e-02, -1.1195e-01,\n",
      "          7.5589e-02, -3.3239e-01,  1.2702e-01, -1.0099e-01, -8.4449e-02,\n",
      "          1.1334e-01,  1.0601e-01, -2.4695e-01, -7.6249e-02]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(best_net.fc2.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
