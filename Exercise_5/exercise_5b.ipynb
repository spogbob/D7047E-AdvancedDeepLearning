{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# From: https://github.com/jasonicarter/MNIST-adversarial-images/blob/master/MNIST-adversarial-images.ipynb\n",
    "# Dependencies for entire notebook here\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow_datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "#mnist = tensorflow_datasets.load('mnist')\n",
    "mnist = tf.keras.datasets.mnist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras.datasets.mnist' has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\Fabian\\AppData\\Local\\Temp\\ipykernel_4188\\3121962376.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Take a look the training data\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Training.images shape: '\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmnist\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimages\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Training.labels shape: '\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmnist\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Shape of an image: '\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmnist\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimages\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Example label: '\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmnist\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'keras.api._v2.keras.datasets.mnist' has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "# Take a look the training data\n",
    "print('Training.images shape: ', mnist.train.images.shape)\n",
    "print('Training.labels shape: ', mnist.train.labels.shape)\n",
    "print('Shape of an image: ', mnist.train.images[0].shape)\n",
    "print('Example label: ', mnist.train.labels[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Review a few images\n",
    "image_list = mnist.train.images[0:9]\n",
    "image_list_labels = mnist.train.labels[0:9]\n",
    "\n",
    "# https://matplotlib.org/mpl_toolkits/axes_grid/users/overview.html#imagegrid\n",
    "fig = plt.figure(1, (5., 5.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(3, 3),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.3,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for i in range(len(image_list)):\n",
    "    image = image_list[i].reshape(28,28)\n",
    "    grid[i].imshow(image)\n",
    "    grid[i].set_title('Label: {0}'.format(image_list_labels[i].argmax()))\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# To run nicely in jupyter notebook\n",
    "sess = tf.InteractiveSession()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Functions for creating weights and biases\n",
    "# https://www.tensorflow.org/get_started/mnist/pros\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# Functions for convolution and pooling functions\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pooling_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create placeholders nodes for images and label inputs\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# y = (Wx +b)\n",
    "# https://www.tensorflow.org/get_started/mnist/pros\n",
    "\n",
    "# Input layer\n",
    "x_image = tf.reshape(x, [-1,28,28,1]) # mnist image comes in as 784 vector\n",
    "\n",
    "# Conv layer 1 - 32x5x5\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "x_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "x_pool1 = max_pooling_2x2(x_conv1)\n",
    "\n",
    "# Conv layer 2 - 64x5x5\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "x_conv2 = tf.nn.relu(conv2d(x_pool1, W_conv2) + b_conv2)\n",
    "x_pool2 = max_pooling_2x2(x_conv2)\n",
    "\n",
    "# Flatten - keras 'flatten'\n",
    "x_flat = tf.reshape(x_pool2, [-1, 7*7*64])\n",
    "\n",
    "# Dense fully connected layer\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024]) # max pooling reduced image to 7x7\n",
    "b_fc1 = bias_variable([1024])\n",
    "x_fc1 = tf.nn.relu(tf.matmul(x_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Regularization with dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "x_fc1_drop = tf.nn.dropout(x_fc1, keep_prob)\n",
    "\n",
    "# Classification layer\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y_conv = tf.matmul(x_fc1_drop, W_fc2) + b_fc2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Probabilities - output from model (not the same as logits)\n",
    "y = tf.nn.softmax(y_conv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setup to test accuracy of model\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initilize all global variables\n",
    "sess.run(tf.global_variables_initializer())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train model\n",
    "# Run once to get the model to a good confidence level\n",
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    if i%200 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.4})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run trained model against test data\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images[0:500],\n",
    "                                                  y_: mnist.test.labels[0:500], keep_prob: 1.0}))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_predictions(image_list, output_probs=False, adversarial=False):\n",
    "    '''\n",
    "    Evaluate images against trained model and plot images.\n",
    "    If adversarial == True, replace middle image title appropriately\n",
    "    Return probability list if output_probs == True\n",
    "    '''\n",
    "    prob = y.eval(feed_dict={x: image_list, keep_prob: 1.0})\n",
    "\n",
    "    pred_list = np.zeros(len(image_list)).astype(int)\n",
    "    pct_list = np.zeros(len(image_list)).astype(int)\n",
    "\n",
    "    # Setup image grid\n",
    "    import math\n",
    "    cols = 3\n",
    "    rows = math.ceil(image_list.shape[0]/cols)\n",
    "    fig = plt.figure(1, (12., 12.))\n",
    "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                     nrows_ncols=(rows, cols),  # creates grid of axes\n",
    "                     axes_pad=0.5,  # pad between axes in inch.\n",
    "                     )\n",
    "\n",
    "    # Get probs, images and populate grid\n",
    "    for i in range(len(prob)):\n",
    "        pred_list[i] = np.argmax(prob[i]) # for mnist index == classification\n",
    "        pct_list[i] = prob[i][pred_list[i]] * 100\n",
    "\n",
    "        image = image_list[i].reshape(28,28)\n",
    "        grid[i].imshow(image)\n",
    "\n",
    "        grid[i].set_title('Label: {0} \\nCertainty: {1}%' \\\n",
    "                          .format(pred_list[i],\n",
    "                                  pct_list[i]))\n",
    "\n",
    "        # Only use when plotting original, partial deriv and adversarial images\n",
    "        if (adversarial) & (i % 3 == 1):\n",
    "            grid[i].set_title(\"Adversarial \\nPartial Derivatives\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return prob if output_probs else None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get 10 4s [:,4] from top 500 [0:500], nonzero returns tuple, get index[0], then first 10 [0:10]\n",
    "index_of_4s = np.nonzero(mnist.test.labels[0:500][:,4])[0][0:10]\n",
    "x_batch = mnist.test.images[index_of_4s]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_predictions(x_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Mostly inspired by:\n",
    "# https://codewords.recurse.com/issues/five/why-do-neural-networks-think-a-panda-is-a-vulture\n",
    "def create_plot_adversarial_images(x_image, y_label, lr=0.1, n_steps=1, output_probs=False):\n",
    "\n",
    "    original_image = x_image\n",
    "    probs_per_step = []\n",
    "\n",
    "    # Calculate loss, derivative and create adversarial image\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/train/gradient_computation\n",
    "    loss =  tf.nn.softmax_cross_entropy_with_logits(labels=y_label, logits=y_conv)\n",
    "    deriv = tf.gradients(loss, x)\n",
    "    image_adv = tf.stop_gradient(x - tf.sign(deriv)*lr/n_steps)\n",
    "    image_adv = tf.clip_by_value(image_adv, 0, 1) # prevents -ve values creating 'real' image\n",
    "\n",
    "    for _ in range(n_steps):\n",
    "        # Calculate derivative and adversarial image\n",
    "        dydx = sess.run(deriv, {x: x_image, keep_prob: 1.0}) # can't seem to access 'deriv' w/o running this\n",
    "        x_adv = sess.run(image_adv, {x: x_image, keep_prob: 1.0})\n",
    "\n",
    "        # Create darray of 3 images - orig, noise/delta, adversarial\n",
    "        x_image = np.reshape(x_adv, (1, 784))\n",
    "        img_adv_list = original_image\n",
    "        img_adv_list = np.append(img_adv_list, dydx[0], axis=0)\n",
    "        img_adv_list = np.append(img_adv_list, x_image, axis=0)\n",
    "\n",
    "        # Print/plot images and return probabilities\n",
    "        probs = plot_predictions(img_adv_list, output_probs=output_probs, adversarial=True)\n",
    "        probs_per_step.append(probs) if output_probs else None\n",
    "\n",
    "    return probs_per_step"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\Fabian\\AppData\\Local\\Temp\\ipykernel_4188\\2855310300.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Pick a random 2 image from first 1000 images\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;31m# Create adversarial image and with target label 6\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mindex_of_4s\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnonzero\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmnist\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m1000\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mrand_index\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex_of_4s\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mimage_norm\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmnist\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimages\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mindex_of_4s\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mrand_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Pick a random 2 image from first 1000 images\n",
    "# Create adversarial image and with target label 6\n",
    "index_of_4s = np.nonzero(mnist.test.labels[0:1000][:,4])[0]\n",
    "rand_index = np.random.randint(0, len(index_of_4s))\n",
    "image_norm = mnist.test.images[index_of_4s[rand_index]]\n",
    "image_norm = np.reshape(image_norm, (1, 784))\n",
    "label_adv = [0,0,0,0,0,0,0,0,0,1] # one hot encoded, adversarial label 6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot adversarial images\n",
    "# Over each step, model certainty changes from 2 to 6\n",
    "create_plot_adversarial_images(image_norm, label_adv, lr=0.2, n_steps=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sess.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}