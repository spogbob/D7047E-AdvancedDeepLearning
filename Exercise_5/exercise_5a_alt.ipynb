{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#source: https://github.com/wiseodd/generative-models/blob/master/GAN/vanilla_gan/gan_pytorch.py\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "from torchvision import datasets, transforms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "11501568/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#load mnist data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "def create_mnist_dataset(data, labels, batch_size):\n",
    "  def gen():\n",
    "    for image, label in zip(data, labels):\n",
    "        yield image, label\n",
    "  ds = tf.data.Dataset.from_generator(gen, (tf.float32, tf.int32), ((28,28 ), ()))\n",
    "\n",
    "  return ds.repeat().batch(batch_size)\n",
    "\n",
    "#train and validation dataset with different batch size\n",
    "mnist = create_mnist_dataset(x_train, y_train, 64)\n",
    "#valid_dataset = create_mnist_dataset(x_test, y_test, 20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "#mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)\n",
    "\n",
    "mb_size = 64\n",
    "Z_dim = 100\n",
    "#X_dim = mnist.train.images.shape[1]\n",
    "#y_dim = mnist.train.labels.shape[1]\n",
    "X_dim = 28\n",
    "y_dim = 28\n",
    "h_dim = 128\n",
    "c = 0\n",
    "lr = 1e-3\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST('./mnist_data/', train=True, download=True,\n",
    "                             transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "                             batch_size=mb_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST('./mnist_data/', train=False, download=True,\n",
    "                             transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "                             batch_size=mb_size, shuffle=True)\n",
    "\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "    return Variable(torch.randn(*size) * xavier_stddev, requires_grad=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "#Generator\n",
    "Wzh = xavier_init(size=[Z_dim, h_dim])\n",
    "bzh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Whx = xavier_init(size=[h_dim, X_dim])\n",
    "bhx = Variable(torch.zeros(X_dim), requires_grad=True)\n",
    "\n",
    "\n",
    "def G(z):\n",
    "    h = torch.relu(z @ Wzh + bzh.repeat(z.size(0), 1))\n",
    "    print(h.size())\n",
    "    X = torch.sigmoid(h @ Whx + bhx.repeat(h.size(0), 1))\n",
    "    print(X.size())\n",
    "    return X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "#Discriminator\n",
    "Wxh = xavier_init(size=[X_dim, h_dim])\n",
    "bxh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Why = xavier_init(size=[h_dim, 1])\n",
    "bhy = Variable(torch.zeros(1), requires_grad=True)\n",
    "\n",
    "\n",
    "def D(X):\n",
    "    lokjo = bxh.repeat(X.size(0), 1)\n",
    "    print(lokjo.size())\n",
    "    h = torch.relu(X @ Wxh + lokjo)\n",
    "    print(h.size())\n",
    "    y = torch.sigmoid(h @ Why + bhy.repeat(h.size(0), 1))\n",
    "    print(y.size())\n",
    "    return y\n",
    "\n",
    "\n",
    "G_params = [Wzh, bzh, Whx, bhx]\n",
    "D_params = [Wxh, bxh, Why, bhy]\n",
    "params = G_params + D_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def reset_grad():\n",
    "    for p in params:\n",
    "        if p.grad is not None:\n",
    "            data = p.grad.data\n",
    "            p.grad = Variable(data.new().resize_as_(data).zero_())\n",
    "\n",
    "\n",
    "G_solver = optim.Adam(G_params, lr=1e-3)\n",
    "D_solver = optim.Adam(D_params, lr=1e-3)\n",
    "\n",
    "ones_label = Variable(torch.ones(mb_size, 1))\n",
    "zeros_label = Variable(torch.zeros(mb_size, 1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64, 28])\n",
      "torch.Size([64, 128])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (28) must match the size of tensor b (64) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\Fabian\\AppData\\Local\\Temp\\ipykernel_11572\\2380487600.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     16\u001B[0m             \u001B[1;31m# Dicriminator forward-loss-backward-update\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m             \u001B[0mG_sample\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mG\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mz\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m             \u001B[0mD_real\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mD\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m             \u001B[0mD_fake\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mD\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mG_sample\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\Fabian\\AppData\\Local\\Temp\\ipykernel_11572\\1321121366.py\u001B[0m in \u001B[0;36mD\u001B[1;34m(X)\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[0mlokjo\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbxh\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrepeat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlokjo\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m     \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m \u001B[1;33m@\u001B[0m \u001B[0mWxh\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mlokjo\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m     \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msigmoid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m \u001B[1;33m@\u001B[0m \u001B[0mWhy\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mbhy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrepeat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The size of tensor a (28) must match the size of tensor b (64) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "#for it in range(20000):\n",
    "it = 0\n",
    "my_range = 20000\n",
    "for epoch in range(int(my_range / 60000 + 1)):\n",
    "    for _, data in enumerate(train_loader, 0):\n",
    "        if it < my_range:\n",
    "            # Sample data\n",
    "            z = Variable(torch.randn(mb_size, Z_dim))\n",
    "            #X, _ = mnist.train.next_batch(mb_size)\n",
    "            #X = Variable(torch.from_numpy(X))\n",
    "            X, _ = data\n",
    "\n",
    "            print(X.size())\n",
    "\n",
    "            # Dicriminator forward-loss-backward-update\n",
    "            G_sample = G(z)\n",
    "            D_real = D(X)\n",
    "            D_fake = D(G_sample)\n",
    "\n",
    "            D_loss_real = nn.binary_cross_entropy(D_real, ones_label)\n",
    "            D_loss_fake = nn.binary_cross_entropy(D_fake, zeros_label)\n",
    "            D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "            D_loss.backward()\n",
    "            D_solver.step()\n",
    "\n",
    "            # Housekeeping - reset gradient\n",
    "            reset_grad()\n",
    "\n",
    "            # Generator forward-loss-backward-update\n",
    "            z = Variable(torch.randn(mb_size, Z_dim))\n",
    "            G_sample = G(z)\n",
    "            D_fake = D(G_sample)\n",
    "\n",
    "            G_loss = nn.binary_cross_entropy(D_fake, ones_label)\n",
    "\n",
    "            G_loss.backward()\n",
    "            G_solver.step()\n",
    "\n",
    "            # Housekeeping - reset gradient\n",
    "            reset_grad()\n",
    "\n",
    "            # Print and plot every now and then\n",
    "            if it % 1000 == 0:\n",
    "                print('Iter-{}; D_loss: {}; G_loss: {}'.format(it, D_loss.data.numpy(), G_loss.data.numpy()))\n",
    "\n",
    "                samples = G(z).data.numpy()[:16]\n",
    "\n",
    "                fig = plt.figure(figsize=(4, 4))\n",
    "                gs = gridspec.GridSpec(4, 4)\n",
    "                gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "                #for i, sample in enumerate(samples):\n",
    "                #    ax = plt.subplot(gs[i])\n",
    "                #    plt.axis('off')\n",
    "                #    ax.set_xticklabels([])\n",
    "                #    ax.set_yticklabels([])\n",
    "                #    ax.set_aspect('equal')\n",
    "                #    plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "                if not os.path.exists('out/'):\n",
    "                    os.makedirs('out/')\n",
    "\n",
    "                #plt.savefig('out/{}.png'.format(str(c).zfill(3)), bbox_inches='tight')\n",
    "                c += 1\n",
    "                #plt.close(fig)\n",
    "\n",
    "            it = it + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}