{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "\n",
    "# Tensorboard for visualizing\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import Tiny Shakespeare"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model from https://github.com/spro/char-rnn.pytorch/blob/master/model.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, model=\"gru\", n_layers=1):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.model = model.lower()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        if self.model == \"gru\":\n",
    "            self.rnn = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        elif self.model == \"lstm\":\n",
    "            self.rnn = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        batch_size = input.size(0)\n",
    "        encoded = self.encoder(input)\n",
    "        output, hidden = self.rnn(encoded.view(1, batch_size, -1), hidden)\n",
    "        output = self.decoder(output.view(batch_size, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def forward2(self, input, hidden):\n",
    "        encoded = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.rnn(encoded.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        if self.model == \"lstm\":\n",
    "            return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)),\n",
    "                    Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)))\n",
    "        return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### generate.py from https://github.com/spro/char-rnn.pytorch/blob/master/generate.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# https://github.com/spro/char-rnn.pytorch\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from helpers import *\n",
    "from model import *\n",
    "\n",
    "def generate(decoder, prime_str='A', predict_len=100, temperature=0.8, cuda=False):\n",
    "    hidden = decoder.init_hidden(1)\n",
    "    prime_input = Variable(char_tensor(prime_str).unsqueeze(0))\n",
    "\n",
    "    if cuda:\n",
    "        hidden = hidden.cuda()\n",
    "        prime_input = prime_input.cuda()\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[:,p], hidden)\n",
    "\n",
    "    inp = prime_input[:,-1]\n",
    "\n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "\n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "\n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = Variable(char_tensor(predicted_char).unsqueeze(0))\n",
    "        if cuda:\n",
    "            inp = inp.cuda()\n",
    "\n",
    "    return predicted\n",
    "\n",
    "# Run as standalone script\n",
    "if __name__ == '__main__':\n",
    "\n",
    "# Parse command line arguments\n",
    "    argparser = argparse.ArgumentParser()\n",
    "    argparser.add_argument('filename', type=str)\n",
    "    argparser.add_argument('-p', '--prime_str', type=str, default='A')\n",
    "    argparser.add_argument('-l', '--predict_len', type=int, default=100)\n",
    "    argparser.add_argument('-t', '--temperature', type=float, default=0.8)\n",
    "    argparser.add_argument('--cuda', action='store_true')\n",
    "    args = argparser.parse_args()\n",
    "\n",
    "    decoder = torch.load(args.filename)\n",
    "    del args.filename\n",
    "    print(generate(decoder, **vars(args)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### helpers.py from https://github.com/spro/char-rnn.pytorch/blob/master/helpers.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://github.com/spro/char-rnn.pytorch\n",
    "\n",
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "\n",
    "# Reading and un-unicode-encoding data\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "def read_file(filename):\n",
    "    file = unidecode.unidecode(open(filename).read())\n",
    "    return file, len(file)\n",
    "\n",
    "# Turning a string into a tensor\n",
    "\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        try:\n",
    "            tensor[c] = all_characters.index(string[c])\n",
    "        except:\n",
    "            continue\n",
    "    return tensor\n",
    "\n",
    "# Readable time elapsed\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### train.py from https://github.com/spro/char-rnn.pytorch/blob/master/train.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# https://github.com/spro/char-rnn.pytorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helpers import *\n",
    "from model import *\n",
    "from generate import *\n",
    "\n",
    "# Parse command line arguments\n",
    "argparser = argparse.ArgumentParser()\n",
    "argparser.add_argument('filename', type=str)\n",
    "argparser.add_argument('--model', type=str, default=\"gru\")\n",
    "argparser.add_argument('--n_epochs', type=int, default=2000)\n",
    "argparser.add_argument('--print_every', type=int, default=100)\n",
    "argparser.add_argument('--hidden_size', type=int, default=100)\n",
    "argparser.add_argument('--n_layers', type=int, default=2)\n",
    "argparser.add_argument('--learning_rate', type=float, default=0.01)\n",
    "argparser.add_argument('--chunk_len', type=int, default=200)\n",
    "argparser.add_argument('--batch_size', type=int, default=100)\n",
    "argparser.add_argument('--shuffle', action='store_true')\n",
    "argparser.add_argument('--cuda', action='store_true')\n",
    "args = argparser.parse_args()\n",
    "\n",
    "if args.cuda:\n",
    "    print(\"Using CUDA\")\n",
    "\n",
    "file, file_len = read_file(args.filename)\n",
    "\n",
    "def random_training_set(chunk_len, batch_size):\n",
    "    inp = torch.LongTensor(batch_size, chunk_len)\n",
    "    target = torch.LongTensor(batch_size, chunk_len)\n",
    "    for bi in range(batch_size):\n",
    "        start_index = random.randint(0, file_len - chunk_len)\n",
    "        end_index = start_index + chunk_len + 1\n",
    "        chunk = file[start_index:end_index]\n",
    "        inp[bi] = char_tensor(chunk[:-1])\n",
    "        target[bi] = char_tensor(chunk[1:])\n",
    "    inp = Variable(inp)\n",
    "    target = Variable(target)\n",
    "    if args.cuda:\n",
    "        inp = inp.cuda()\n",
    "        target = target.cuda()\n",
    "    return inp, target\n",
    "\n",
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden(args.batch_size)\n",
    "    if args.cuda:\n",
    "        hidden = hidden.cuda()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for c in range(args.chunk_len):\n",
    "        output, hidden = decoder(inp[:,c], hidden)\n",
    "        loss += criterion(output.view(args.batch_size, -1), target[:,c])\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / args.chunk_len\n",
    "\n",
    "def save():\n",
    "    save_filename = os.path.splitext(os.path.basename(args.filename))[0] + '.pt'\n",
    "    torch.save(decoder, save_filename)\n",
    "    print('Saved as %s' % save_filename)\n",
    "\n",
    "# Initialize models and start training\n",
    "\n",
    "decoder = CharRNN(\n",
    "    n_characters,\n",
    "    args.hidden_size,\n",
    "    n_characters,\n",
    "    model=args.model,\n",
    "    n_layers=args.n_layers,\n",
    ")\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=args.learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if args.cuda:\n",
    "    decoder.cuda()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "try:\n",
    "    print(\"Training for %d epochs...\" % args.n_epochs)\n",
    "    for epoch in tqdm(range(1, args.n_epochs + 1)):\n",
    "        loss = train(*random_training_set(args.chunk_len, args.batch_size))\n",
    "        loss_avg += loss\n",
    "\n",
    "        if epoch % args.print_every == 0:\n",
    "            print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / args.n_epochs * 100, loss))\n",
    "            print(generate(decoder, 'Wh', 100, cuda=args.cuda), '\\n')\n",
    "\n",
    "    print(\"Saving...\")\n",
    "    save()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Saving before quit...\")\n",
    "    save()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}