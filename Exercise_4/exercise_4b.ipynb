{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_tokenizer(text):\n",
    "    '''\n",
    "    Takes a text and returns a list of the individual words\n",
    "    Args:\n",
    "        text (str): The text to tokenize\n",
    "    Returns ([str]): A list of individual words\n",
    "    '''\n",
    "    ## WRITE A TOKENIZER (Hint: use the 'split' function)\n",
    "    return text.split()\n",
    "\n",
    "class SimpleVocabulary():\n",
    "\n",
    "    def __init__(self, corpus):\n",
    "        '''\n",
    "        Takes a corpus, tokenizes it, and sets the internal variables needed\n",
    "        to return the index of any given word (and what word has a given index)\n",
    "        Args:\n",
    "            corpus ([str]): The corpus as a list of non-tokenized texts\n",
    "        '''\n",
    "        ## WRITE A FUNCTION TO INITIALIZE THE VOCABULARY\n",
    "        # HINT: Create a dictionary that contains the index for each unique word and antother to contain the word for a given index\n",
    "        # HINT: Each new, previously unseen token from the tokenized corpus, should be entered into the dictionaries\n",
    "\n",
    "        current_index = 0\n",
    "        self.token2index = {}\n",
    "        self.index2token = []\n",
    "        for text in corpus:\n",
    "            for word in simple_tokenizer(text):\n",
    "                if word not in self.token2index:\n",
    "                    self.index2token.append(word)\n",
    "                    self.token2index.update({word : current_index})\n",
    "                    current_index += 1\n",
    "\n",
    "\n",
    "    def get_index(self, token):\n",
    "        '''\n",
    "        Takes a token and returns the index of that token\n",
    "        Args:\n",
    "            token (str): A token\n",
    "        Returns (int): The index of the given token\n",
    "        '''\n",
    "        ## WRITE A FUNCTION THAT RETURNS THE INDEX OF A GIVEN TOKEN\n",
    "        return self.token2index.get(token)\n",
    "\n",
    "\n",
    "    def get_token(self, index):\n",
    "        '''\n",
    "        Takes an index and returns the token that index represents\n",
    "        Args:\n",
    "            index (int): An index\n",
    "        Returns (str): The token that the given index represents\n",
    "        '''\n",
    "        ## WRITE A FUNCTION THAT RETURNS THE TOKEN OF A GIVEN INDEX\n",
    "        return self.index2token[index]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Returns (int): The number of words in the vocabulary\n",
    "        '''\n",
    "        ## WRITE A FUNCTION THAT RETURNS THE LENGTH OF THE VOCABULARY\n",
    "        return len(self.token2index)\n",
    "\n",
    "def index_sequence(sequence, vocabulary):\n",
    "    '''\n",
    "    Takes a tokenized text and a vocabulary and returns an indexed sequence\n",
    "    Args:\n",
    "        sequence ([str]): A list of individual tokens\n",
    "    Returns ([int]): A list of indexes\n",
    "    '''\n",
    "\n",
    "    return [vocabulary.get_index(token) for token in sequence]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}